"""
Summarizer Agent - æ‘˜è¦ç”Ÿæˆä»£ç†
ç«¯å£ï¼š8002
åŠŸèƒ½ï¼šç”Ÿæˆæ–‡æœ¬æ‘˜è¦

ä½¿ç”¨ Google A2A SDK (0.3.8) å®ç°æ ‡å‡†çš„ Agent-to-Agent åè®®
ä½¿ç”¨ OpenAI GPT-4o-mini è¿›è¡Œæ™ºèƒ½æ‘˜è¦
"""
from a2a.server.apps import A2AFastAPIApplication
from a2a.types import AgentCard, Message, Part, TextPart, Role, AgentCapabilities, AgentSkill, MessageSendParams
from a2a.server.request_handlers import RequestHandler
import uvicorn
import os, uuid
import json
try:
    from openai import AsyncOpenAI as _OpenAIClient  # OpenAI >=1.x async client
except Exception:  # pragma: no cover
    from openai import OpenAI as _SyncOpenAIClient  # fallback
    _OpenAIClient = None  # type: ignore
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class SummarizerHandler:
    """æ‘˜è¦ç”Ÿæˆé€»è¾‘å¤„ç†å™¨"""

    def __init__(self):
        self.model = "gpt-4o-mini"
        api_key = os.getenv("OPENAI_API_KEY")
        if _OpenAIClient:
            # async client
            self.client = _OpenAIClient(api_key=api_key)
            self._async = True
        else:
            # sync fallback
            self.client = _SyncOpenAIClient(api_key=api_key)  # type: ignore
            self._async = False

    async def handle_message(self, message: Message) -> Message:
        # æå–ç”¨æˆ·æ–‡æœ¬
        user_text = ""
        for part in message.parts:
            if isinstance(part.root, TextPart):
                user_text = part.root.text
                break
        summary = await self._generate_summary(user_text)
        return Message(
            message_id=str(uuid.uuid4()),
            role=Role.agent,
            parts=[Part(root=TextPart(text=summary))]
        )

    async def _generate_summary(self, text: str) -> str:
        """è°ƒç”¨ GPT-4o-mini ç”Ÿæˆæ‘˜è¦ï¼›è‹¥è¶…æ—¶æˆ–å¤±è´¥ï¼Œé™çº§ä¸ºæœ¬åœ°å¿«é€Ÿæ‘˜è¦ã€‚

        é™çº§ç­–ç•¥ï¼š
        1. å–é¦–æ®µ/é¦– 3~5 å¥
        2. æå–å‡ºç°é¢‘æ¬¡è¾ƒé«˜çš„å…³é”®è¯ï¼ˆç®€å•åˆ†è¯æŒ‰ä¸­æ–‡/è‹±æ–‡è¯åˆ‡åˆ†ï¼‰
        """
        cleaned = text.strip()
        if not cleaned:
            return "# æ‘˜è¦\n\n(ç©ºè¾“å…¥)"

        # è¾“å…¥è¿‡é•¿å…ˆæˆªæ–­ï¼Œå‡å°‘å¤–éƒ¨è°ƒç”¨æ—¶é—´
        MAX_INPUT = 4000  # chars
        truncated = cleaned[:MAX_INPUT]

        prompt = f"""è¯·ä¸ºä»¥ä¸‹æ–‡æœ¬ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„ Markdown æ‘˜è¦ï¼š
è¦æ±‚ï¼š
1. å…ˆç»™ 2-3 å¥æ€»ä½“æ¦‚è¿°
2. ç”¨é¡¹ç›®ç¬¦å·åˆ—å‡º 3-6 ä¸ªå…³é”®è¦ç‚¹
3. ç»™å‡º 5-10 ä¸ªå…³é”®è¯
4. ä¿ç•™åŸæ–‡ä¸­é‡è¦æ•°å­—æˆ–æ—¥æœŸ

æ–‡æœ¬ï¼ˆå¯èƒ½å·²æˆªæ–­è‡³å‰ {MAX_INPUT} ä¸ªå­—ç¬¦ï¼‰ï¼š
{truncated}
"""

        try:
            if getattr(self, "_async", False):
                resp_obj = await self.client.chat.completions.create(  # type: ignore[attr-defined]
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯å†™ä½œä¸ä¿¡æ¯æç‚¼åŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.4,
                    max_tokens=800,
                    timeout=25,  # OpenAI SDK æ”¯æŒæ—¶ç”Ÿæ•ˆ
                )
                response = resp_obj
            else:
                import asyncio
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥è°ƒç”¨ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                def _call_sync():
                    return self.client.chat.completions.create(  # type: ignore
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æŠ€æœ¯å†™ä½œä¸ä¿¡æ¯æç‚¼åŠ©æ‰‹ã€‚"},
                            {"role": "user", "content": prompt},
                        ],
                        temperature=0.4,
                        max_tokens=800,
                    )
                response = await asyncio.to_thread(_call_sync)

            choices = getattr(response, "choices", [])  # type: ignore
            first = choices[0] if choices else None
            content = getattr(getattr(first, "message", None), "content", "") if first else ""
            summary = (content or "").strip()
            summary += (
                f"\n\n---\n**ç»Ÿè®¡ä¿¡æ¯**\n- åŸæ–‡é•¿åº¦: {len(cleaned)}\n"
                f"- å¤„ç†é•¿åº¦: {len(truncated)}\n- æ‘˜è¦é•¿åº¦: {len(summary)}\n- æ¨¡å‹: {self.model}\n"
            )
            return summary
        except Exception as e:  # noqa: BLE001
            print(f"[summarizer] âŒ LLM è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é™çº§æ‘˜è¦: {e}")
            return self._fallback_summary(truncated, original_len=len(cleaned))

    def _fallback_summary(self, text: str, original_len: int) -> str:
        import re
        # å–å‰ 5 å¥ï¼ˆæŒ‰å¥å·/æ¢è¡Œ/ä¸­æ–‡æ ‡ç‚¹æ‹†åˆ†ï¼‰
        sentences = [s.strip() for s in re.split(r'[ã€‚.!?\n]', text) if s.strip()]
        head = sentences[:5]
        head_block = "\n- " + "\n- ".join(head) if head else "(å†…å®¹è¿‡çŸ­)"
        # å…³é”®è¯ï¼ˆç®€å•ï¼šæŒ‰éå­—æ¯æ•°å­—ä¸­æ–‡åˆ‡åˆ†ï¼Œç»Ÿè®¡é¢‘æ¬¡ï¼‰
        tokens = re.split(r'[^0-9A-Za-z\u4e00-\u9fff]+', text)
        freq = {}
        for t in tokens:
            if len(t) < 2:
                continue
            freq[t] = freq.get(t, 0) + 1
        keywords = sorted(freq.items(), key=lambda x: x[1], reverse=True)[:10]
        kw_line = ", ".join(k for k, _ in keywords) if keywords else "æ— "
        return (
            f"# ç®€è¦æ‘˜è¦ (é™çº§)\n\n**åŸæ–‡é•¿åº¦**: {original_len}\n\n**è¦ç‚¹**:{head_block}\n\n**å…³é”®è¯**: {kw_line}\n"
        )


class SummarizerRequestHandler(RequestHandler):
    def __init__(self, logic: SummarizerHandler):
        self.logic = logic

    async def on_message_send(self, params: MessageSendParams, context=None):  # type: ignore[override]
        return await self.logic.handle_message(params.message)

    async def on_get_task(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_cancel_task(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_message_send_stream(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_resubscribe_to_task(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_set_task_push_notification_config(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_get_task_push_notification_config(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_list_task_push_notification_config(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError
    async def on_delete_task_push_notification_config(self, params, context=None):  # type: ignore[override]
        raise NotImplementedError


if __name__ == "__main__":
    # å®šä¹‰ AgentCard
    agent_card = AgentCard(
        name="Summarizer Agent",
        description="ç”Ÿæˆæ–‡æœ¬æ‘˜è¦å’Œå…³é”®ä¿¡æ¯æå–",
        version="1.0.0",
        url="http://localhost:8002",
        capabilities=AgentCapabilities(streaming=False, push_notifications=False),
        default_input_modes=["text/plain"],
        default_output_modes=["text/plain"],
        skills=[
            AgentSkill(
                id="summarize",
                name="ç”Ÿæˆæ‘˜è¦",
                description="å¯¹é•¿æ–‡æœ¬ç”Ÿæˆç®€æ´æ‘˜è¦",
                tags=["summarization", "nlp", "text-processing"],
                examples=[
                    "å¯¹ä»¥ä¸‹æ–°é—»ç”Ÿæˆæ‘˜è¦ï¼š...",
                    "æå–å…³é”®ä¿¡æ¯ï¼š...",
                    "æ€»ç»“ä¸€ä¸‹è¿™ç¯‡æ–‡ç« ",
                ],
                input_modes=["text/plain"],
                output_modes=["text/plain"],
            )
        ],
    )

    logic = SummarizerHandler()
    handler = SummarizerRequestHandler(logic)
    app_wrapper = A2AFastAPIApplication(agent_card, handler)
    fastapi_app = app_wrapper.build()
    print("[summarizer] âœ… FastAPI app æ„å»ºå®Œæˆå¹¶ç»‘å®šè·¯ç”±")
    print("ğŸš€ Summarizer Agent å¯åŠ¨: http://localhost:8002")
    uvicorn.run(fastapi_app, host="0.0.0.0", port=8002)
