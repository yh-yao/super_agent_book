from typing import Dict, Tuple

from .improver import Improver
from .scorer import overall_score

from .llm_backend import OpenAIBackend


class SelfEvolvingAgent:
    """è‡ªè¿›åŒ–å•†ä¸šæŠ¥å‘Šç”Ÿæˆä»£ç†ã€‚"""
    
    def __init__(self):
        self.improver = Improver()
        self.llm = OpenAIBackend()

    def _init_params(self) -> Dict:
        """åˆå§‹åŒ–é»˜è®¤å‚æ•°ã€‚"""
        params = {
            "bullet_prob": 0.55,
            "target_words": 800,  # å•†ä¸šæŠ¥å‘Šéœ€è¦æ›´å¤šå­—æ•°
            "temperature": 0.2
        }
        params["prefer_bullets"] = bool(
            params.get("bullet_prob", 0.55) >= 0.55
        )
        return params

    def _generate_report(self, prompt: str, params: Dict) -> str:
        """ä½¿ç”¨LLMåç«¯ç”ŸæˆæŠ¥å‘Šã€‚"""
        return self.llm.generate_report(prompt, params)

    def run(
        self, 
        source_text: str, 
        steps: int = 5, 
        target_score: float = 0.86,
        target_words: int = 800
    ) -> Tuple[str, Dict]:
        """è¿è¡Œè‡ªè¿›åŒ–å•†ä¸šæŠ¥å‘Šç”Ÿæˆæµç¨‹ã€‚"""
        params = self._init_params()
        # ä½¿ç”¨ä¼ å…¥çš„ç›®æ ‡å­—æ•°è¦†ç›–é»˜è®¤å€¼
        params["target_words"] = target_words
        context = ""  # ä¸Šä¸‹æ–‡ä»ç©ºå¼€å§‹ï¼Œé€šè¿‡æœç´¢ç§¯ç´¯
        # åœ¨æç¤ºè¯ä¸­æ˜ç¡®æŒ‡å®šç›®æ ‡å­—æ•°
        prompt = f"{source_text}\n\nè¦æ±‚ï¼šè¯·ç”Ÿæˆçº¦{target_words}å­—çš„è¯¦ç»†æŠ¥å‘Šã€‚"  # ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
        draft = ''
        best_report, best_score = draft, {"total": -1.0}
        history = []

        print(f"\nğŸš€ å¼€å§‹è‡ªè¿›åŒ–æŠ¥å‘Šç”Ÿæˆæµç¨‹ï¼Œç›®æ ‡ï¼š{steps}æ­¥ï¼Œ{target_words}å­—")
        print("=" * 60)

        for i in range(1, steps + 1):
            print(f"\nğŸ“ æ­¥éª¤ {i}/{steps}")
            print("-" * 40)
            
            # æ¯æ¬¡è¿­ä»£éƒ½è¿›è¡Œåæ€å†³ç­–ï¼ˆæœç´¢æˆ–ä¿®è®¢ï¼‰
            print("ğŸ¤” æ­£åœ¨åæ€å†³ç­–...")
            decision = self.llm.reflect_and_decide(
                prompt=prompt, context=context, draft=draft
            )
            
            if decision.get("action") == "search":
                query = decision.get("query", "")
                print(f"ğŸ” å†³å®šæœç´¢ï¼š{query}")
                
                results = decision.get("results", [])
                print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªæœç´¢ç»“æœ")
                
                snippets = " ".join([
                    r.get("snippet", "") for r in results 
                    if isinstance(r, dict)
                ])
                context += (
                    f"\n[æœç´¢ç»“æœï¼š{query}]\n"
                    f"{snippets}\n"
                )
                history.append({
                    "step": i, 
                    "action": "search", 
                    "query": query,
                    "search_results": results  # ä¿å­˜å®Œæ•´çš„æœç´¢ç»“æœ
                })
                # æœç´¢åé‡æ–°ç”ŸæˆæŠ¥å‘Š
                print("âœï¸  åŸºäºæœç´¢ç»“æœé‡æ–°ç”ŸæˆæŠ¥å‘Š...")
                full_context = f"{prompt}\n{context}" if context else prompt
                draft = self._generate_report(full_context, params)
            elif decision.get("action") == "revise" and draft:
                print("âœï¸  å†³å®šä¿®è®¢å½“å‰æŠ¥å‘Š...")
                # ä½¿ç”¨ LLM çš„ä¿®è®¢ç»“æœï¼Œä¸å†é‡æ–°ç”Ÿæˆ
                draft = decision.get("new_text", draft)
            else:
                print("ğŸ“ ç”Ÿæˆåˆå§‹æŠ¥å‘Š...")
                # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¿­ä»£æˆ–å…¶ä»–æƒ…å†µï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š
                full_context = f"{prompt}\n{context}" if context else prompt
                draft = self._generate_report(full_context, params)

            # å†è¯„ä¼°æŠ¥å‘Šè´¨é‡
            print("ğŸ“Š è¯„ä¼°æŠ¥å‘Šè´¨é‡...")
            evaluation_text = f"æç¤ºè¯ï¼š{source_text}\nç”Ÿæˆçš„æŠ¥å‘Šï¼š{draft}"
            s = overall_score(
                evaluation_text, 
                draft, 
                target_words=target_words,
                prefer_bullets=bool(params.get("prefer_bullets", False))
            )
            
            print(f"ğŸ“ˆ å½“å‰å¾—åˆ†: {s['total']:.3f} (ç›®æ ‡: {target_score})")
            print(f"   - ç›¸å…³æ€§: {s['relevance']:.3f}")
            print(f"   - å®Œæ•´æ€§: {s['completeness']:.3f}")
            print(f"   - é•¿åº¦åŒ¹é…: {s['length_fit']:.3f}")
            print(f"   - ç»“æ„: {s['structure']:.3f}")
            print(f"   - å†—ä½™åº¦: {s['redundancy']:.3f}")
            
            history.append({
                "step": i, 
                "action": "generate_and_score", 
                "score": s, 
                "summary": draft
            })
            
            if s["total"] > best_score["total"]:
                best_report, best_score = draft, s
                print(f"ğŸ‰ å‘ç°æ›´å¥½çš„æŠ¥å‘Šï¼æ–°æœ€ä½³å¾—åˆ†: {s['total']:.3f}")
                
            if s["total"] >= target_score:
                print(f"ğŸ† è¾¾åˆ°ç›®æ ‡åˆ†æ•° {target_score}ï¼Œæå‰ç»“æŸï¼")
                break
                
            # æ ¹æ®è¯„ä¼°ç»“æœæ”¹è¿›å‚æ•°ï¼Œä¸ºä¸‹ä¸€æ¬¡è¿­ä»£åšå‡†å¤‡
            print("ğŸ”§ æ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´å‚æ•°...")
            params = self.improver.step(params, s)

        print(f"\nâœ… æµç¨‹å®Œæˆï¼æœ€ç»ˆæœ€ä½³å¾—åˆ†: {best_score['total']:.3f}")
        print("=" * 60)

        learned = {
            "bullet_prob": float(params.get("bullet_prob", 0.55)),
            "target_words": target_words
        }
        
        # æ±‡æ€»æ‰€æœ‰æœç´¢ç»“æœ
        all_search_results = []
        for entry in history:
            if entry.get("action") == "search" and "search_results" in entry:
                all_search_results.append({
                    "step": entry["step"],
                    "query": entry["query"],
                    "results": entry["search_results"]
                })
        
        return best_report, {
            "best_score": best_score, 
            "history": history,
            "search_summary": all_search_results,
            "learned_params": learned
        }
