# client/openai_client.py
# MCP + OpenAI é›†æˆç¤ºä¾‹ï¼šä½¿ç”¨ OpenAI çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½æ¥è°ƒç”¨ MCP å·¥å…·
import asyncio
import os
import sys
import json
from pathlib import Path
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI

async def main():
    """
    æ¼”ç¤ºå¦‚ä½•å°† MCP å·¥å…·ä¸ OpenAI çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½é›†æˆã€‚
    OpenAI æ¨¡å‹ä¼šå†³å®šä½•æ—¶è°ƒç”¨å“ªäº› MCP å·¥å…·æ¥å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚
    """
    
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    # ç¡®ä¿è®¾ç½®äº† OPENAI_API_KEY ç¯å¢ƒå˜é‡
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    print("=" * 60)
    print("ğŸ¤– MCP + OpenAI é›†æˆæ¼”ç¤º")
    print("=" * 60)
    print()
    
    # å¯åŠ¨ MCP æœåŠ¡å™¨
    env = dict(os.environ)
    env["PYTHONUNBUFFERED"] = "1"
    
    server_script = Path(__file__).parent.parent / "src" / "mcp_demo" / "server.py"
    
    server = StdioServerParameters(
        command=sys.executable,
        args=["-u", str(server_script)],
        env=env,
    )
    
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ MCP æœåŠ¡å™¨...")
    
    async with stdio_client(server) as (read, write):
        async with ClientSession(read, write) as session:
            # åˆå§‹åŒ– MCP ä¼šè¯
            await session.initialize()
            print("âœ… MCP æœåŠ¡å™¨å·²è¿æ¥\n")
            
            # è·å–å¯ç”¨çš„ MCP å·¥å…·
            tools_resp = await session.list_tools()
            print(f"ğŸ“‹ å‘ç° {len(tools_resp.tools)} ä¸ªå¯ç”¨å·¥å…·:")
            for tool in tools_resp.tools:
                print(f"   â€¢ {tool.name}: {tool.description}")
            print()
            
            # å°† MCP å·¥å…·è½¬æ¢ä¸º OpenAI å‡½æ•°æ ¼å¼
            openai_tools = []
            for tool in tools_resp.tools:
                openai_tool = {
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description or "",
                        "parameters": tool.inputSchema
                    }
                }
                openai_tools.append(openai_tool)
            
            # ç”¨æˆ·æŸ¥è¯¢ç¤ºä¾‹
            user_queries = [
                "è¯·å¸®æˆ‘è®¡ç®— 15.5 åŠ  24.3 ç­‰äºå¤šå°‘ï¼Ÿ",
                "è¯·è¯»å– hello.txt æ–‡ä»¶çš„å†…å®¹",
                "è¯·å¸®æˆ‘æœç´¢ä¸€ä¸‹ Python MCP ç›¸å…³çš„ä¿¡æ¯"
            ]
            
            for query in user_queries:
                print("=" * 60)
                print(f"ğŸ’¬ ç”¨æˆ·: {query}")
                print("-" * 60)
                
                # æ„å»ºå¯¹è¯æ¶ˆæ¯
                messages = [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"
                    },
                    {
                        "role": "user",
                        "content": query
                    }
                ]
                
                # è°ƒç”¨ OpenAI API
                response = openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    tools=openai_tools,
                    tool_choice="auto"
                )
                
                assistant_message = response.choices[0].message
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·
                if assistant_message.tool_calls:
                    print(f"ğŸ”§ AI å†³å®šè°ƒç”¨å·¥å…·:")
                    
                    # å°†åŠ©æ‰‹çš„å“åº”æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                    messages.append(assistant_message)
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    for tool_call in assistant_message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)
                        
                        print(f"   â†’ {tool_name}({tool_args})")
                        
                        # é€šè¿‡ MCP è°ƒç”¨å®é™…çš„å·¥å…·
                        try:
                            result = await session.call_tool(tool_name, tool_args)
                            tool_result = str(result.content)
                            print(f"   âœ“ å·¥å…·è¿”å›: {tool_result[:100]}...")
                            
                            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": tool_result
                            })
                        except Exception as e:
                            error_msg = f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
                            print(f"   âœ— {error_msg}")
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "content": error_msg
                            })
                    
                    # è·å–æœ€ç»ˆå“åº”
                    final_response = openai_client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=messages
                    )
                    
                    final_message = final_response.choices[0].message.content
                    print(f"\nğŸ¤– AI: {final_message}")
                else:
                    # ç›´æ¥è¿”å›å“åº”ï¼ˆæ— éœ€å·¥å…·ï¼‰
                    print(f"ğŸ¤– AI: {assistant_message.content}")
                
                print()
            
            print("=" * 60)
            print("âœ… æ¼”ç¤ºå®Œæˆï¼")
            print("=" * 60)

if __name__ == "__main__":
    # æ£€æŸ¥ API å¯†é’¥
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   ç¤ºä¾‹: export OPENAI_API_KEY='your-api-key-here'")
        sys.exit(1)
    
    asyncio.run(main())
